{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Line magic function `%cython` not found (But cell magic `%%cython` exists, did you mean that instead?).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython\n",
    "%time\n",
    "%cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yvonnelau/anaconda/lib/python2.7/site-packages/cffi/model.py:526: UserWarning: 'point_conversion_form_t' has no values explicitly defined; next version will refuse to guess which integer type it is meant to be (unsigned/signed, int/long)\n",
      "  % self._get_c_name())\n"
     ]
    }
   ],
   "source": [
    "#import needed packages\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# nltk processing\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import yaml\n",
    "\n",
    "cfg = yaml.safe_load(open('_inc.yaml'))\n",
    "cnx = mysql.connector.connect(user=cfg['mysql']['user'], password=cfg['mysql']['pwd'],\n",
    "                            host=cfg['mysql']['server'], database=cfg['mysql']['db'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load games dataset\n",
    "games = pd.read_sql_query(\"select * from tblGame;\", cnx)\n",
    "# load tv shows dataset\n",
    "tv = pd.read_sql_query(\"select * from tblTVShow;\", cnx)\n",
    "# load movies dataset\n",
    "movies = pd.read_sql_query(\"select * from tblMovie;\", cnx) \n",
    "# load Reviews\n",
    "reviews = pd.read_sql_query(\"select * from tblReview;\", cnx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = games[['uniqueID']].append(movies[['uniqueID']]).append(tv[['uniqueID']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Ginger: Beyond the Crystal is a very good pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>JoJo’s Bizarre Adventure: Eyes in Heaven featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Crew does a lot of things right. Not only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Playing as Batgirl is not quite as interesting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The frantic nature of the gameplay coupled wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID                                               text\n",
       "0         1  \"Ginger: Beyond the Crystal is a very good pla...\n",
       "1         2  JoJo’s Bizarre Adventure: Eyes in Heaven featu...\n",
       "2         3  The Crew does a lot of things right. Not only ...\n",
       "3         4  Playing as Batgirl is not quite as interesting...\n",
       "4         5  The frantic nature of the gameplay coupled wit..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a unique review corpus\n",
    "review_docs = subset.groupby(['uniqueID'])['text'].apply(lambda x: ''.join(x)).reset_index()\n",
    "review_docs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "review_docs = pd.merge(ids[['uniqueID']], review_docs, on = \"uniqueID\", how = \"left\")\n",
    "# substitute null for \"\"\n",
    "review_docs.loc[np.any(review_docs.isnull(), axis = 1),'text'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwrds = stopwords.words('english')\n",
    "# aux function to clean up text\n",
    "def cleaning_text(sentence):\n",
    "    sentence = str(sentence)\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('[^\\w\\s]',' ', sentence)\n",
    "    sentence = re.sub('_',' ', sentence)\n",
    "    sentence = re.sub('\\d+',' ', sentence)\n",
    "    cleaned = ' '.join([w for w in sentence.split() if not w in stopwrds])\n",
    "    cleaned = ' '.join([w for w , pos in pos_tag(cleaned.split()) if (pos == 'NN' or pos=='JJ' or pos=='JJR' or pos=='JJS' )])\n",
    "    cleaned = ' '.join([w for w in cleaned.split() if not len(w)<=2 ])\n",
    "    cleaned = cleaned.strip()\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up review docs, add utf8 encoding\n",
    "review_docs['textClean'] = review_docs.apply(lambda row: cleaning_text(row['text'].encode(\"utf8\")), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a few functions for doc2vec processing\n",
    "def split_sentence(sentence):\n",
    "    words = re.split('\\W+', sentence.lower())\n",
    "    return [word for word in words if word != \"\"]\n",
    "\n",
    "# MyDocs reading from a data frame\n",
    "class MyDocs(object):\n",
    "    def __iter__(self):\n",
    "        for i in range(review_docs.shape[0]):\n",
    "            yield doc2vec.LabeledSentence(words=split_sentence(review_docs.iloc[i,2]), tags=['%s' % review_docs.iloc[i,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the doc2vec model\n",
    "mydocs = MyDocs()\n",
    "model = doc2vec.Doc2Vec(mydocs, size = 200, window = 8, min_count = 5, workers = 4)\n",
    "model.save(\"review.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('princess', 0.5448439121246338), ('inexpensive', 0.5323823094367981), ('eshop', 0.5036611557006836), ('qforce', 0.49544674158096313), ('deluxe', 0.4932363033294678)]\n"
     ]
    }
   ],
   "source": [
    "# testing similar words\n",
    "print model.most_similar(positive=[\"cheap\", \"zelda\"], negative=[\"slow\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save a pickle file\n",
    "import pickle\n",
    "\n",
    "with open('models/model_critic_only.pickle', 'wb') as handle:\n",
    "    pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A world destroyed by a crystal explosion, a my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Featuring a new two-on-two battle system, larg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Strap in for a ride that will find you infiltr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>When The Joker kidnaps Commissioner Gordon and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The world has been dominated by dark forces si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID                                            summary\n",
       "0         1  A world destroyed by a crystal explosion, a my...\n",
       "1         2  Featuring a new two-on-two battle system, larg...\n",
       "2         3  Strap in for a ride that will find you infiltr...\n",
       "3         4  When The Joker kidnaps Commissioner Gordon and...\n",
       "4         5  The world has been dominated by dark forces si..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a unique summary corpus\n",
    "summary_docs = games[['uniqueID','summary']].append(movies[['uniqueID', 'summary']]).append(tv[['uniqueID','summary']])\n",
    "summary_docs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean up summary docs, add utf8 encoding when there is no None Type\n",
    "summary_docs['textClean'] = summary_docs.apply(lambda row: row['summary'] if row['summary'] is None else cleaning_text(row['summary'].encode(\"utf8\")), axis=1)\n",
    "summary_docs.loc[np.any(summary_docs.isnull(), axis = 1), 'textClean'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define class for summary Doc2vec\n",
    "\n",
    "# MyDocs reading from a data frame\n",
    "class MyDocs_summary(object):\n",
    "    def __iter__(self):\n",
    "        for i in range(summary_docs.shape[0]):\n",
    "            yield doc2vec.LabeledSentence(words=split_sentence(summary_docs.iloc[i,2]), tags=['%s' % summary_docs.iloc[i,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train the doc2vec model on summary\n",
    "mydocs_summary = MyDocs_summary()\n",
    "model_summary = doc2vec.Doc2Vec(mydocs_summary, size = 200, window = 8, min_count = 5, workers = 4)\n",
    "model_summary.save(\"summary.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('peter', 0.9542904496192932), ('hobbit', 0.9482103586196899), ('author', 0.9464740753173828), ('robert', 0.9445735216140747), ('penultimate', 0.9298714399337769)]\n"
     ]
    }
   ],
   "source": [
    "# testing similar words\n",
    "print model_summary.most_similar(positive=[\"cheap\", \"zelda\"], negative=[\"slow\"], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combining both summary and critic reviews doc2vec :model_summary and model \n",
    "summary_critics_docvecs = np.zeros(shape=(len(model_summary.docvecs),400))\n",
    "for i in range(len(model_summary.docvecs)):\n",
    "    summary_critics_docvecs[i] = np.concatenate((model_summary.docvecs[i],model.docvecs[i]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save pickle file\n",
    "import pickle\n",
    "with open('summary_critics_docvecs.pickle', 'wb') as handle:\n",
    "    pickle.dump(summary_critics_docvecs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "####### TEST REC FROM HERE\n",
    "# For the app, the code for the recommendation would load a pickle from this cell\n",
    "\n",
    "#to load a pickle file\n",
    "with open('summary_critics_docvecs.pickle', 'rb') as f:\n",
    "    summary_critics_docvecs = pickle.load(f)\n",
    "    \n",
    "# Auxiliary functions for simple recommendation system \n",
    "\n",
    "# Calculate cosine similarity between two vecotrs \n",
    "def cossim(v1, v2): \n",
    "    return np.dot(v1, v2) / np.sqrt(np.dot(v1, v1)) / np.sqrt(np.dot(v2, v2)) \n",
    "\n",
    "# return top_n values from a list\n",
    "def top_n_index(l,n):\n",
    "    return sorted(range(len(l)), key=lambda i: l[i])[-(n+1):-1] #-1 to take off the own product from the returned index list\n",
    "\n",
    "# return a list of unique_id for a given category[\"games\", \"movies\",\"tv\"]\n",
    "def category_id_range(category_list):\n",
    "    # range of ids for each category\n",
    "    games_range = range(1,20417)\n",
    "    movies_range = range(20417, 25887)\n",
    "    tv_range = range(25887, 27865)\n",
    "    \n",
    "    category_range = []\n",
    "    for i in category_list:\n",
    "        if i==\"games\":\n",
    "            category_range = category_range + games_range\n",
    "        elif i==\"movies\":\n",
    "            category_range = category_range + movies_range\n",
    "        else:\n",
    "            category_range = category_range + tv_range\n",
    "    \n",
    "    return category_range\n",
    "\n",
    "def content_recommend(item_id, top_n, inputs, category_list):\n",
    "    input_vec = inputs[item_id - 1]\n",
    "    \n",
    "    #compute similarity array\n",
    "    sim_array = map(lambda v: cossim(input_vec, v), inputs)\n",
    "    \n",
    "    # recommendation's index (set to 50 to get enough to filter out later)\n",
    "    recommendation_index = top_n_index(sim_array, 500)\n",
    "    \n",
    "    # recommendation's unique id\n",
    "    recommendation_unique_id = [i+1 for i in recommendation_index]\n",
    "    \n",
    "    # recommendation's cossim values\n",
    "    recommendation_cossim = [sim_array[i] for i in recommendation_index]\n",
    "    \n",
    "    top_products = zip(recommendation_unique_id, recommendation_cossim)\n",
    "    \n",
    "    # get the range of unique id for a given category prefered by user\n",
    "    category_range = category_id_range(category_list)\n",
    "    \n",
    "    result = [i for i in top_products if i[0] in category_range]\n",
    "    \n",
    "    return result[-top_n:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############# Testing content-based recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save a pickle file\n",
    "import pickle\n",
    "\n",
    "with open('summary_critics_docvecs.pickle', 'rb') as f:\n",
    "    summary_critics_docvecs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products_dataset = games[['uniqueID', 'name']].append(movies[['uniqueID','name']]).append(tv[['uniqueID','name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between two vecotrs \n",
    "def cossim(v1, v2): \n",
    "    return np.dot(v1, v2) / np.sqrt(np.dot(v1, v1)) / np.sqrt(np.dot(v2, v2)) \n",
    "\n",
    "# return top_n values from a list\n",
    "def top_n_index(l,n):\n",
    "    return sorted(range(len(l)), key=lambda i: l[i])[-(n+1):-1] #-1 to take off the own product from the returned index list\n",
    "\n",
    "\n",
    "# returns a dataframe with top_n products with cosine similarity score\n",
    "def recommend(item_id, top_n, products_dataset, inputs):\n",
    "    input_vec = inputs[item_id - 1]\n",
    "    \n",
    "    #compute similarity array\n",
    "    sim_array = map(lambda v: cossim(input_vec, v), inputs)\n",
    "    \n",
    "    # recommendation's index and unique_id\n",
    "    recommendation_index = top_n_index(sim_array, top_n)\n",
    "    recommendation_unique_id = [i+1 for i in top_n_index(sim_array, top_n)]\n",
    "    \n",
    "    # return list of products \n",
    "    top_products = copy.deepcopy(products_dataset[products_dataset['uniqueID'].isin(recommendation_unique_id)])\n",
    "    \n",
    "     # initialize an empty column for cosine similarity\n",
    "    top_products['cossim']=0\n",
    "    \n",
    "    for i in range(len(recommendation_index)):\n",
    "        # YL note: avoid top_products['cossim'].loc[index[i],] = sim_array[index[i]], results in error\n",
    "        top_products.loc[top_products['uniqueID']==recommendation_unique_id[i],'cossim'] = sim_array[recommendation_index[i]]\n",
    "    return top_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>26958</td>\n",
       "      <td>Quantico: Season 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      uniqueID                name\n",
       "1071     26958  Quantico: Season 1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_dataset.loc[products_dataset['name'].str.contains('Quantico')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396    Mario Tennis: Ultra Smash\n",
      "Name: name, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>name</th>\n",
       "      <th>cossim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>1506</td>\n",
       "      <td>Super Smash Bros. Brawl</td>\n",
       "      <td>0.711475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>3398</td>\n",
       "      <td>Mario Power Tennis</td>\n",
       "      <td>0.725986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6757</th>\n",
       "      <td>6758</td>\n",
       "      <td>Sega Superstars Tennis</td>\n",
       "      <td>0.721680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7791</th>\n",
       "      <td>7792</td>\n",
       "      <td>Virtua Tennis 4</td>\n",
       "      <td>0.733592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11851</th>\n",
       "      <td>11852</td>\n",
       "      <td>Super Smash Bros. for Wii U</td>\n",
       "      <td>0.720178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uniqueID                         name    cossim\n",
       "1505       1506      Super Smash Bros. Brawl  0.711475\n",
       "3397       3398           Mario Power Tennis  0.725986\n",
       "6757       6758       Sega Superstars Tennis  0.721680\n",
       "7791       7792              Virtua Tennis 4  0.733592\n",
       "11851     11852  Super Smash Bros. for Wii U  0.720178"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = 397\n",
    "print products_dataset[products_dataset['uniqueID']==id]['name']\n",
    "recommend(id, 5, products_dataset, summary_critics_docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
